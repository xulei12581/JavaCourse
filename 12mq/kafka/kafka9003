#broker的全局唯一编号，不能重复
broker.id=3
 
#处理网络请求的线程数量，也就是接收消息的线程数。
#接收线程会将接收到的消息放到内存中，然后再从内存中写入磁盘。
num.network.threads=3
 
#消息从内存中写入磁盘是时候使用的线程数量。
#用来处理磁盘IO的线程数量
num.io.threads=8
 
#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400
 
#接受套接字的缓冲区大小
socket.receive.buffer.bytes=102400
 
#请求套接字的缓冲区大小
socket.request.max.bytes=104857600
 
#kafka运行日志存放的路径
log.dirs=/export/servers/logs/kafka-logs3
 
#topic在当前broker上的分片个数
num.partitions=1
 
#我们知道segment文件默认会被保留7天的时间，超时的话就
#会被清理，那么清理这件事情就需要有一些线程来做。这里就是
#用来设置恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.stats.log.replication.factor=1
transaction.stats.log.min.isr=1
 
#segment文件保留的最长时间，默认保留7天（168小时），
#超时将被删除，也就是说7天之前的数据将被清理掉。
log.retention.hours=168
 
#日志文件中每个segment的大小，默认为1G
log.segment.bytes=1073741824
 
#上面的参数设置了每一个segment文件的大小是1G，那么
#就需要有一个东西去定期检查segment文件有没有达到1G，
#多长时间去检查一次，就需要设置一个周期性检查文件大小
#的时间（单位是毫秒）。
log.retention.check.interval.ms=300000
 
#zookeeper链接超时时间
zookeeper.connection.timeout.ms=6000
 
#删除topic需要server.properties中设置delete.topic.enable=true否则只是标记删除
delete.topic.enable=true

group.inital.rebalance.delay.ms=0

message.max.bytes=5000000

listeners=PLAINTEXT://localhost:9003

advertised.listeners=PLAINTEXT://localhost:9003
 
broker.list=localhost:9001,localhost:9002,localhost:9003

zookeeper.connect=localhost:2181